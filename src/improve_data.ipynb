{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7479d5",
   "metadata": {},
   "source": [
    "# Amélioration des données\n",
    "\n",
    "Ici, on utilise des NLP pour obtenir des données provenant des notes des patients. On évalueras plus tard ces NLP dans `check_improvement.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea3fa0",
   "metadata": {},
   "source": [
    "**Librairies et données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9168e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from spacy import displacy\n",
    "import edsnlp, edsnlp.pipes as eds\n",
    "\n",
    "input_dir = \"../data_clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f0b87b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Il faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook (../data_clean/df_person.pkl n'existe pas).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     df_person \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_person.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     df_bio \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_bio.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data_clean/df_person.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     df_facteur_risque \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_facteur_risque.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIl faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m n\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexiste pas).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Il faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook (../data_clean/df_person.pkl n'existe pas)."
     ]
    }
   ],
   "source": [
    "assert os.path.exists(input_dir), f\"Il faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook ({input_dir} n'existe pas).\"\n",
    "\n",
    "try:\n",
    "    df_person = pd.read_pickle(os.path.join(input_dir, 'df_person.pkl'))\n",
    "    df_bio = pd.read_pickle(os.path.join(input_dir, 'df_bio.pkl'))\n",
    "    df_note = pd.read_pickle(os.path.join(input_dir, 'df_note.pkl'))\n",
    "    df_visit = pd.read_pickle(os.path.join(input_dir, 'df_visit.pkl'))\n",
    "    df_condition = pd.read_pickle(os.path.join(input_dir, 'df_condition.pkl'))\n",
    "    df_facteur_risque = pd.read_pickle(os.path.join(input_dir, 'df_facteur_risque.pkl'))\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"Il faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook ({e.filename} n'existe pas).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4dd752",
   "metadata": {},
   "source": [
    "**Définition des NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f489e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-06 16:10:46.929\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36medsnlp.pipes.qualifiers.family.family\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m171\u001b[0m - \u001b[33m\u001b[1mYou have requested that the pipeline use annotations provided by the `section` pipeline, but it was not set. Skipping that step.\u001b[0m\n",
      "\u001b[32m2025-06-06 16:10:47.016\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36medsnlp.pipes.qualifiers.family.family\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m171\u001b[0m - \u001b[33m\u001b[1mYou have requested that the pipeline use annotations provided by the `section` pipeline, but it was not set. Skipping that step.\u001b[0m\n",
      "\u001b[32m2025-06-06 16:10:47.032\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36medsnlp.pipes.qualifiers.family.family\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m171\u001b[0m - \u001b[33m\u001b[1mYou have requested that the pipeline use annotations provided by the `section` pipeline, but it was not set. Skipping that step.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<edsnlp.pipes.qualifiers.negation.negation.NegationQualifier at 0x13e84ce50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_smoker = edsnlp.blank(\"eds\")\n",
    "nlp_smoker.add_pipe(eds.sentences())\n",
    "nlp_smoker.add_pipe(eds.normalizer())\n",
    "nlp_smoker.add_pipe(eds.tobacco())\n",
    "nlp_smoker.add_pipe(eds.negation())\n",
    "nlp_smoker.add_pipe(eds.family())\n",
    "\n",
    "nlp_alcool = edsnlp.blank(\"eds\")\n",
    "nlp_alcool.add_pipe(eds.sentences())\n",
    "nlp_alcool.add_pipe(eds.normalizer()) \n",
    "nlp_alcool.add_pipe(eds.alcohol())\n",
    "nlp_alcool.add_pipe(eds.negation())\n",
    "nlp_alcool.add_pipe(eds.family())\n",
    "\n",
    "terms = dict(\n",
    "    cancer_sein = [\n",
    "    \"pilule\",\n",
    "    \"sterilet\",\n",
    "    \"preservatif\",\n",
    "    \"implant\",\n",
    "    \"patch\",\n",
    "    \"anneau\",\n",
    "    \"diaphragme\",\n",
    "    \"spermicide\",\n",
    "    \"ligature\"\n",
    "]\n",
    ")\n",
    "nlp_contraception = edsnlp.blank(\"eds\")\n",
    "nlp_contraception.add_pipe(eds.sentences())\n",
    "nlp_contraception.add_pipe(eds.normalizer())\n",
    "nlp_contraception.add_pipe(eds.matcher(\n",
    "    terms=terms,\n",
    "    attr=\"NORM\",\n",
    "))\n",
    "nlp_contraception.add_pipe(eds.family())\n",
    "nlp_contraception.add_pipe(eds.negation())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ab6f2",
   "metadata": {},
   "source": [
    "**Éxecution du NLP fumeur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total notes: 996\n",
      "Total fumeurs: 90\n"
     ]
    }
   ],
   "source": [
    "df_facteur_risque['fumeur'] = False\n",
    "\n",
    "smokers, total = 0, 0\n",
    "for i in range(len(df_note)):\n",
    "    note = df_note.iloc[i]\n",
    "    text = note['note_text']\n",
    "    doc = nlp_smoker(text)\n",
    "\n",
    "    filtered_ents_for_display = [ent for ent in doc.ents if not ent._.family] # Exclure les entités de la famille\n",
    "    filtered_ents_for_display = [ent for ent in filtered_ents_for_display if not ent._.negation] # Exclure les entités négatives\n",
    "\n",
    "    visit_id_from_sampled_note = note['visit_occurrence_id']\n",
    "    matching_visit_rows = df_visit[df_visit['visit_occurrence_id'] == visit_id_from_sampled_note]\n",
    "\n",
    "    current_note_id_scalar = note['note_id']\n",
    "    person_id = matching_visit_rows['person_id'].iloc[0]\n",
    "   \n",
    "    total += 1\n",
    "    if filtered_ents_for_display: \n",
    "        smokers += 1\n",
    "        df_facteur_risque.loc[df_facteur_risque['person_id'] == person_id, 'fumeur'] = True\n",
    "\n",
    "print(f\"Total notes: {total}\")\n",
    "print(f\"Total fumeurs: {smokers}\")\n",
    "\n",
    "pd.to_pickle(df_facteur_risque, os.path.join(input_dir, 'df_facteur_risque.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0746c7",
   "metadata": {},
   "source": [
    "**Éxecution du NLP alcool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f72ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total notes: 996\n",
      "Total consomateurs d'alcool: 22\n"
     ]
    }
   ],
   "source": [
    "df_facteur_risque['alcool'] = False\n",
    "\n",
    "alcohol, total = 0, 0\n",
    "\n",
    "for i in range(len(df_note)):\n",
    "    note = df_note.iloc[i]\n",
    "    text = note['note_text']\n",
    "    doc = nlp_alcool(text)\n",
    "\n",
    "    filtered_ents_for_display = [ent for ent in doc.ents if not ent._.family] # On enleve les labels liées à la famille\n",
    "    filtered_ents_for_display = [ent for ent in filtered_ents_for_display if not ent._.negation] # On enleve les labels qui ont été négés\n",
    "\n",
    "    visit_id_from_sampled_note = note['visit_occurrence_id']\n",
    "    matching_visit_rows = df_visit[df_visit['visit_occurrence_id'] == visit_id_from_sampled_note]\n",
    "\n",
    "    current_note_id_scalar = note['note_id']\n",
    "    person_id = matching_visit_rows['person_id'].iloc[0]\n",
    "   \n",
    "    total += 1\n",
    "    \n",
    "    if filtered_ents_for_display:\n",
    "        alcohol += 1\n",
    "        #df_facteur_risque.loc[df_facteur_risque['person_id'] == person_id, 'alcool'] = True\n",
    "        # On fait le choix de ne pas mettre à jour le df_facteur_risque pour l'alcool avec le NLP, car il y a trop de faux positifs du a une ligne presente dans le\n",
    "        # traitement conseillé au patient\n",
    "        \n",
    "        \n",
    "print(f\"Total notes: {total}\")\n",
    "print(f\"Total consomateurs d'alcool: {alcohol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a45a4",
   "metadata": {},
   "source": [
    "**Éxecution du NLP contraception**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360d943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total notes: 996\n",
      "Total utilisatrices de contraception: 0\n"
     ]
    }
   ],
   "source": [
    "df_facteur_risque['contraception'] = False\n",
    "\n",
    "contraception, total = 0, 0\n",
    "\n",
    "for i in range(len(df_note)):\n",
    "    note = df_note.iloc[i]\n",
    "    text = note['note_text']\n",
    "    doc = nlp_contraception(text)\n",
    "\n",
    "    filtered_ents_for_display = [ent for ent in doc.ents if not ent._.family] # On enleve les labels liées à la famille\n",
    "    filtered_ents_for_display = [ent for ent in filtered_ents_for_display if not ent._.negation] # On enleve les labels qui ont été négés\n",
    "\n",
    "    visit_id_from_sampled_note = note['visit_occurrence_id']\n",
    "    matching_visit_rows = df_visit[df_visit['visit_occurrence_id'] == visit_id_from_sampled_note]\n",
    "\n",
    "    current_note_id_scalar = note['note_id']\n",
    "    person_id = matching_visit_rows['person_id'].iloc[0]\n",
    "   \n",
    "    total += 1\n",
    "\n",
    "    if filtered_ents_for_display:\n",
    "        contraception += 1\n",
    "        df_facteur_risque.loc[df_facteur_risque['person_id'] == person_id, 'contraception'] = True\n",
    "        \n",
    "print(f\"Total notes: {total}\")\n",
    "print(f\"Total utilisatrices de contraception: {contraception}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988dd32",
   "metadata": {},
   "source": [
    "**Note importante:** Après avoir réalisé que la contraception ne marcherais pas, et en vérifiant a l'oeil qu'il n'y avait en effet pas de contraception mentionnée dans les documents, nous l'avons exclus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

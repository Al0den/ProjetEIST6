{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e5cc85",
   "metadata": {},
   "source": [
    "# Évaluation de l'amélioration des données\n",
    "\n",
    "Dans ce fichier, on cherche a évaluer les compétences du NLP, dans l'objectif de calculer sa précision et son rappel. Ceux-ci sont calculé dans `statistics.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10708458",
   "metadata": {},
   "source": [
    "**Librairies et données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317d3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import edsnlp, edsnlp.pipes as eds\n",
    "\n",
    "from spacy import displacy\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "input_dir = \"../data_clean/\"\n",
    "visuals_dir = \"../visuals/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adee6bbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Il faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook (../data_clean/df_person.pkl n'existe pas).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     df_person \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_person.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     df_bio \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_bio.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data_clean/df_person.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     df_facteur_risque \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_facteur_risque.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIl faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m n\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexiste pas).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Il faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook (../data_clean/df_person.pkl n'existe pas)."
     ]
    }
   ],
   "source": [
    "assert os.path.exists(input_dir), f\"Il faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook ({input_dir} n'existe pas).\"\n",
    "\n",
    "try:\n",
    "    df_person = pd.read_pickle(os.path.join(input_dir, 'df_person.pkl'))\n",
    "    df_bio = pd.read_pickle(os.path.join(input_dir, 'df_bio.pkl'))\n",
    "    df_note = pd.read_pickle(os.path.join(input_dir, 'df_note.pkl'))\n",
    "    df_visit = pd.read_pickle(os.path.join(input_dir, 'df_visit.pkl'))\n",
    "    df_condition = pd.read_pickle(os.path.join(input_dir, 'df_condition.pkl'))\n",
    "    df_facteur_risque = pd.read_pickle(os.path.join(input_dir, 'df_facteur_risque.pkl'))\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"Il faut exéctuer le script de récolte et nettoyage (clean_data.ipynb) avant de lancer ce notebook ({e.filename} n'existe pas).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb7f9e",
   "metadata": {},
   "source": [
    "**Évaluation du NLP pour les fumeurs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 123, Faux Positifs: 5, Faux Négatifs: 3, True Positifs: 7, True Négatifs: 108\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "\n",
    "faux_positif, faux_negatif = 0, 0\n",
    "fumeurs, non_fumeurs = 0, 0\n",
    "true_positif, true_negatif = 0, 0\n",
    "\n",
    "echantillons = random.shuffle([i for i in range(len(df_person))])\n",
    "\n",
    "for i in echantillons:\n",
    "    person_id = df_person.iloc[i]['person_id']\n",
    "\n",
    "    visit = df_visit[df_visit['person_id'] == person_id].iloc[0]\n",
    "    note = df_note[df_note['visit_occurrence_id'] == visit['visit_occurrence_id']].iloc[0]\n",
    "\n",
    "    print(note['note_text'])\n",
    "\n",
    "    res = input(\"Le patient est-il un fumeur? (y/n): \")\n",
    "    total += 1\n",
    "\n",
    "    fumeur = df_facteur_risque.loc[df_facteur_risque['person_id'] == person_id]['fumeur'].values\n",
    "\n",
    "    if res == 'y':\n",
    "        if fumeur: true_positif += 1\n",
    "        else: faux_negatif += 1\n",
    "    elif res == 'n':\n",
    "        if fumeur: faux_positif += 1\n",
    "        else: true_negatif += 1\n",
    "    else:\n",
    "        total -= 1\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Total: {total}, Faux Positifs: {faux_positif}, Faux Négatifs: {faux_negatif}, True Positifs: {true_positif}, True Négatifs: {true_negatif}\")\n",
    "    \n",
    "    if res == 'exit':\n",
    "        break\n",
    "\n",
    "with open(os.path.join(input_dir, 'fumeur_results.txt'), 'w') as f:\n",
    "    f.write(f\"Total: {total}\\n\")\n",
    "    f.write(f\"Faux Positifs: {faux_positif}\\n\")\n",
    "    f.write(f\"Faux Négatifs: {faux_negatif}\\n\")\n",
    "    f.write(f\"True Positifs: {true_positif}\\n\")\n",
    "    f.write(f\"True Négatifs: {true_negatif}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dfb218",
   "metadata": {},
   "source": [
    "**Évaluation du NLP pour les consommateurs d'alcool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f47ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 26, Faux positifs (alcool) : 26, Faux négatifs (alcool) : 0, Buveurs : 26, Non-buveurs : 0\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "\n",
    "faux_positif_alcool, faux_negatif_alcool = 0, 0\n",
    "non_buveurs, buveurs = 0, 0\n",
    "\n",
    "echantillons = random.shuffle([i for i in range(len(df_person))])\n",
    "\n",
    "for i in echantillons:\n",
    "    person_id = df_person.iloc[i]['person_id']\n",
    "    visit = df_visit[df_visit['person_id'] == person_id].iloc[0]\n",
    "    note = df_note[df_note['visit_occurrence_id'] == visit['visit_occurrence_id']].iloc[0]\n",
    "\n",
    "    alcoolique = df_facteur_risque.loc[df_facteur_risque['person_id'] == person_id]['alcool'].values\n",
    "\n",
    "    if not alcoolique:\n",
    "        continue # On ne considère que les patients avec un facteur de risque alcool, car il y en a trop peu\n",
    "\n",
    "    print(note['note_text'])\n",
    "    res = input(\"Le patient consomme-t-il de l'alcool ? (y/n) : \")\n",
    "\n",
    "    total += 1\n",
    "\n",
    "    if res == 'y':\n",
    "        buveurs += 1\n",
    "    elif res == 'n':\n",
    "        faux_positif_alcool += 1\n",
    "        buveurs += 1\n",
    "    else:\n",
    "        total -= 1\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Total : {total}, Faux positifs (alcool) : {faux_positif_alcool}, \"\n",
    "          f\"Faux négatifs (alcool) : {faux_negatif_alcool}, Buveurs : {buveurs}, Non-buveurs : {non_buveurs}\")\n",
    "\n",
    "    if res == 'exit':\n",
    "        break\n",
    "\n",
    "if total > 10:\n",
    "    with open(os.path.join(input_dir, 'alcool_results.txt'), 'w') as f:\n",
    "        f.write(f\"Total : {total}\\n\")\n",
    "        f.write(f\"Faux positifs (alcool) : {faux_positif_alcool}\\n\")\n",
    "        f.write(f\"Faux négatifs (alcool) : {faux_negatif_alcool}\\n\")\n",
    "        f.write(f\"Buveurs : {buveurs}\\n\")\n",
    "        f.write(f\"Non-buveurs : {non_buveurs}\\n\")\n",
    "else:\n",
    "    print(\"Pas assez de données pour enregistrer les résultats.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
